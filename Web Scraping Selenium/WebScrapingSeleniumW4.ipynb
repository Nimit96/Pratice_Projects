{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f83b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca27585",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d2ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429705a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting url\n",
    "url= \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ed27052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.', '11.', '12.', '13.', '14.', '15.', '16.', '17.', '18.', '19.', '20.', '21.', '22.', '23.', '24.', '25.', '26.', '27.', '28.', '29.', '30.']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "rnk=driver.find_elements_by_xpath(\"//table[3]/tbody/tr/td[1]\")\n",
    "rank=[]\n",
    "for i in rnk:\n",
    "    try:\n",
    "        rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "        \n",
    "print(rank)\n",
    "print(len(rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b13059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Baby Shark Dance\"[22]', '\"Despacito\"[24]', '\"Johny Johny Yes Papa\"[25]', '\"Shape of You\"[26]', '\"See You Again\"[27]', '\"Masha and the Bear – Recipe for Disaster\"[30]', '\"Bath Song\"[31]', '\"Learning Colors – Colorful Eggs on a Farm\"[32]', '\"Uptown Funk\"[33]', '\"Gangnam Style\"[34]', '\"Phonics Song with Two Words\"[36]', '\"Sugar\"[37]', '\"Dame Tu Cosita\"[38]', '\"Sorry\"[39]', '\"Roar\"[40]', '\"Counting Stars\"[41]', '\"Thinking Out Loud\"[42]', '\"Wheels on the Bus\"[43]', '\"Dark Horse\"[44]', '\"Faded\"[45]', '\"Shake It Off\"[46]', '\"Girls Like You\"[47]', '\"Lean On\"[48]', '\"Bailando\"[49]', '\"Let Her Go\"[50]', '\"Mi Gente\"[51]', '\"Perfect\"[52]', '\"Axel F\"[53]', '\"Waka Waka (This Time for Africa)\"[54]', '\"Hello\"[55]']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "vd=driver.find_elements_by_xpath(\"//table[3]/tbody/tr/td[2]\")\n",
    "vdn=[]\n",
    "for i in vd:\n",
    "    try:\n",
    "        vdn.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "print(vdn)\n",
    "print(len(vdn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f73adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Pinkfong Kids' Songs & Stories\", 'Luis Fonsi', 'LooLoo Kids', 'Ed Sheeran', 'Wiz Khalifa', 'Get Movies', 'Cocomelon – Nursery Rhymes', 'Miroshka TV', 'Mark Ronson', 'Psy', 'ChuChu TV', 'Maroon 5', 'El Chombo', 'Justin Bieber', 'Katy Perry', 'OneRepublic', 'Ed Sheeran', 'Cocomelon – Nursery Rhymes', 'Katy Perry', 'Alan Walker', 'Taylor Swift', 'Maroon 5', 'Major Lazer', 'Enrique Iglesias', 'Passenger', 'J Balvin', 'Ed Sheeran', 'Crazy Frog', 'Shakira', 'Adele']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "up=driver.find_elements_by_xpath(\"//table[3]/tbody/tr/td[3]\")\n",
    "upl=[]\n",
    "for i in up:\n",
    "    try:\n",
    "        upl.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "print(upl)\n",
    "print(len(upl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec139a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9.04', '7.46', '5.58', '5.40', '5.19', '4.45', '4.37', '4.31', '4.24', '4.13', '4.02', '3.51', '3.48', '3.45', '3.39', '3.35', '3.29', '3.18', '3.11', '3.10', '3.08', '3.08', '3.07', '3.07', '3.03', '2.95', '2.90', '2.90', '2.89', '2.86']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "vw=driver.find_elements_by_xpath(\"//table[3]/tbody/tr/td[4]\")\n",
    "vws=[]\n",
    "for i in vw:\n",
    "    try:\n",
    "        vws.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "print(vws)\n",
    "print(len(vws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a24cefc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['June 17, 2016', 'January 12, 2017', 'October 8, 2016', 'January 30, 2017', 'April 6, 2015', 'January 31, 2012', 'May 2, 2018', 'February 27, 2018', 'November 19, 2014', 'July 15, 2012', 'March 6, 2014', 'January 14, 2015', 'April 5, 2018', 'October 22, 2015', 'September 5, 2013', 'May 31, 2013', 'October 7, 2014', 'May 24, 2018', 'February 20, 2014', 'December 3, 2015', 'August 18, 2014', 'May 31, 2018', 'March 22, 2015', 'April 11, 2014', 'July 25, 2012', 'June 29, 2017', 'November 9, 2017', 'June 16, 2009', 'June 4, 2010', 'October 22, 2015']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "upd=driver.find_elements_by_xpath(\"//table[3]/tbody/tr/td[5]\")\n",
    "udt=[]\n",
    "for i in upd:\n",
    "    try:\n",
    "        udt.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "print(udt)\n",
    "print(len(udt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67a78266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views (billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.</th>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.</th>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[25]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.</th>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.</th>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[30]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.</th>\n",
       "      <td>\"Bath Song\"[31]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[32]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.</th>\n",
       "      <td>\"Uptown Funk\"[33]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.</th>\n",
       "      <td>\"Gangnam Style\"[34]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.</th>\n",
       "      <td>\"Phonics Song with Two Words\"[36]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.</th>\n",
       "      <td>\"Sugar\"[37]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.</th>\n",
       "      <td>\"Dame Tu Cosita\"[38]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.</th>\n",
       "      <td>\"Sorry\"[39]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.</th>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.</th>\n",
       "      <td>\"Counting Stars\"[41]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.</th>\n",
       "      <td>\"Thinking Out Loud\"[42]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.</th>\n",
       "      <td>\"Wheels on the Bus\"[43]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.</th>\n",
       "      <td>\"Dark Horse\"[44]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.</th>\n",
       "      <td>\"Faded\"[45]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.</th>\n",
       "      <td>\"Shake It Off\"[46]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.</th>\n",
       "      <td>\"Girls Like You\"[47]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.</th>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.</th>\n",
       "      <td>\"Bailando\"[49]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.</th>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.</th>\n",
       "      <td>\"Mi Gente\"[51]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.</th>\n",
       "      <td>\"Perfect\"[52]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.</th>\n",
       "      <td>\"Axel F\"[53]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[54]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.</th>\n",
       "      <td>\"Hello\"[55]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Video Name  \\\n",
       "1.                            \"Baby Shark Dance\"[22]   \n",
       "2.                                   \"Despacito\"[24]   \n",
       "3.                        \"Johny Johny Yes Papa\"[25]   \n",
       "4.                                \"Shape of You\"[26]   \n",
       "5.                               \"See You Again\"[27]   \n",
       "6.    \"Masha and the Bear – Recipe for Disaster\"[30]   \n",
       "7.                                   \"Bath Song\"[31]   \n",
       "8.   \"Learning Colors – Colorful Eggs on a Farm\"[32]   \n",
       "9.                                 \"Uptown Funk\"[33]   \n",
       "10.                              \"Gangnam Style\"[34]   \n",
       "11.                \"Phonics Song with Two Words\"[36]   \n",
       "12.                                      \"Sugar\"[37]   \n",
       "13.                             \"Dame Tu Cosita\"[38]   \n",
       "14.                                      \"Sorry\"[39]   \n",
       "15.                                       \"Roar\"[40]   \n",
       "16.                             \"Counting Stars\"[41]   \n",
       "17.                          \"Thinking Out Loud\"[42]   \n",
       "18.                          \"Wheels on the Bus\"[43]   \n",
       "19.                                 \"Dark Horse\"[44]   \n",
       "20.                                      \"Faded\"[45]   \n",
       "21.                               \"Shake It Off\"[46]   \n",
       "22.                             \"Girls Like You\"[47]   \n",
       "23.                                    \"Lean On\"[48]   \n",
       "24.                                   \"Bailando\"[49]   \n",
       "25.                                 \"Let Her Go\"[50]   \n",
       "26.                                   \"Mi Gente\"[51]   \n",
       "27.                                    \"Perfect\"[52]   \n",
       "28.                                     \"Axel F\"[53]   \n",
       "29.           \"Waka Waka (This Time for Africa)\"[54]   \n",
       "30.                                      \"Hello\"[55]   \n",
       "\n",
       "                             Artist        Upload Date Views (billions)  \n",
       "1.   Pinkfong Kids' Songs & Stories      June 17, 2016             9.04  \n",
       "2.                       Luis Fonsi   January 12, 2017             7.46  \n",
       "3.                      LooLoo Kids    October 8, 2016             5.58  \n",
       "4.                       Ed Sheeran   January 30, 2017             5.40  \n",
       "5.                      Wiz Khalifa      April 6, 2015             5.19  \n",
       "6.                       Get Movies   January 31, 2012             4.45  \n",
       "7.       Cocomelon – Nursery Rhymes        May 2, 2018             4.37  \n",
       "8.                      Miroshka TV  February 27, 2018             4.31  \n",
       "9.                      Mark Ronson  November 19, 2014             4.24  \n",
       "10.                             Psy      July 15, 2012             4.13  \n",
       "11.                       ChuChu TV      March 6, 2014             4.02  \n",
       "12.                        Maroon 5   January 14, 2015             3.51  \n",
       "13.                       El Chombo      April 5, 2018             3.48  \n",
       "14.                   Justin Bieber   October 22, 2015             3.45  \n",
       "15.                      Katy Perry  September 5, 2013             3.39  \n",
       "16.                     OneRepublic       May 31, 2013             3.35  \n",
       "17.                      Ed Sheeran    October 7, 2014             3.29  \n",
       "18.      Cocomelon – Nursery Rhymes       May 24, 2018             3.18  \n",
       "19.                      Katy Perry  February 20, 2014             3.11  \n",
       "20.                     Alan Walker   December 3, 2015             3.10  \n",
       "21.                    Taylor Swift    August 18, 2014             3.08  \n",
       "22.                        Maroon 5       May 31, 2018             3.08  \n",
       "23.                     Major Lazer     March 22, 2015             3.07  \n",
       "24.                Enrique Iglesias     April 11, 2014             3.07  \n",
       "25.                       Passenger      July 25, 2012             3.03  \n",
       "26.                        J Balvin      June 29, 2017             2.95  \n",
       "27.                      Ed Sheeran   November 9, 2017             2.90  \n",
       "28.                      Crazy Frog      June 16, 2009             2.90  \n",
       "29.                         Shakira       June 4, 2010             2.89  \n",
       "30.                           Adele   October 22, 2015             2.86  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT=pd.DataFrame()\n",
    "YT[\"Video Name\"]=vdn\n",
    "YT[\"Artist\"]=upl\n",
    "YT[\"Upload Date\"]=udt\n",
    "YT[\"Views (billions)\"]=vws\n",
    "YT.index=rank\n",
    "YT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1aa7317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e843c31",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "14927bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e2e120a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting url\n",
    "url= \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "# time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "22d9415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intl=driver.find_element_by_xpath(\"//*[text()='International']\").click()\n",
    "fixt=driver.find_element_by_link_text(\"Fixtures\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c0604f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['England v India 2021', 'England v India 2021', 'England v India 2021', 'England v India 2021', 'England v India 2021']\n",
      "['Test', 'Test', 'Test', 'Test', 'Test']\n",
      "['Trent Bridge, Nottingham', \"Lord's, London\", 'Headingley, Leeds', 'The Oval, London', 'Old Trafford, Manchester']\n",
      "['Wednesday 4 August', 'Thursday 12 August', 'Wednesday 25 August', 'Thursday 2 September', 'Friday 10 September']\n",
      "['15:30 IST', '15:30 IST', '15:30 IST', '15:30 IST', '15:30 IST']\n"
     ]
    }
   ],
   "source": [
    "mch=driver.find_elements_by_xpath(\".//div[@class='js-list']/a\")\n",
    "\n",
    "mcth=[]\n",
    "for i in mch:\n",
    "    mcth.append(i.get_attribute(\"href\"))\n",
    "mcth\n",
    "\n",
    "match=[]\n",
    "seris=[]\n",
    "plce=[]\n",
    "dte=[]\n",
    "tme=[]\n",
    "\n",
    "for i in mcth:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        mt=driver.find_element_by_xpath(\"//section[3]/div/ul/li/span[2]\")\n",
    "        match.append(mt.text)\n",
    "    except:\n",
    "        match.append(\"-\")\n",
    "    \n",
    "    try:\n",
    "        srs=driver.find_element_by_xpath(\"//section[3]/div/ul/li[2]/span[2]\")\n",
    "        seris.append(srs.text)\n",
    "    except:\n",
    "        seris.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        plc=driver.find_element_by_xpath(\"//section[3]/div/ul/li[3]/span[2]\")\n",
    "        plce.append(plc.text)\n",
    "    except:\n",
    "        plce.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        dt=driver.find_element_by_xpath(\"//div[@class='mc-header-scorebox__datetime']/strong\")\n",
    "        dte.append(dt.text)\n",
    "    except:\n",
    "        dte.append(\"-\")\n",
    "    try:\n",
    "        tm=driver.find_element_by_xpath(\"//span[@class='mc-header-scorebox__ist-time']\")\n",
    "        tme.append(tm.text)\n",
    "    except:\n",
    "        tme.append(\"-\")\n",
    "    \n",
    "print(match)\n",
    "print(seris)\n",
    "print(plce)\n",
    "print(dte)\n",
    "print(tme)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "69d42182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Test</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>Wednesday 4 August</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Test</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>Thursday 12 August</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Test</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>Wednesday 25 August</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Test</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>Thursday 2 September</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Test</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>Friday 10 September</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Match Title Series                     Place  \\\n",
       "1  England v India 2021   Test  Trent Bridge, Nottingham   \n",
       "2  England v India 2021   Test            Lord's, London   \n",
       "3  England v India 2021   Test         Headingley, Leeds   \n",
       "4  England v India 2021   Test          The Oval, London   \n",
       "5  England v India 2021   Test  Old Trafford, Manchester   \n",
       "\n",
       "                   Date       Time  \n",
       "1    Wednesday 4 August  15:30 IST  \n",
       "2    Thursday 12 August  15:30 IST  \n",
       "3   Wednesday 25 August  15:30 IST  \n",
       "4  Thursday 2 September  15:30 IST  \n",
       "5   Friday 10 September  15:30 IST  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI=pd.DataFrame()\n",
    "ODI[\"Match Title\"]=match\n",
    "ODI[\"Series\"]=seris\n",
    "ODI[\"Place\"]=plce\n",
    "ODI[\"Date\"]=dte\n",
    "ODI[\"Time\"]=tme\n",
    "ODI.index += 1\n",
    "ODI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cd7d7991",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400467e",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13b0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Getting url\n",
    "url= \"https://www.guru99.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa6c2880",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel=driver.find_element_by_xpath(\"//a[contains(text(),'Selenium')]\")\n",
    "sel.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce387c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sele=driver.find_element_by_xpath(\"(.//*[normalize-space(text()) and normalize-space(.)='Selenium Exception Handling (Common Exceptions List)'])[1]/preceding::strong[1]\")\n",
    "sele.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a267c69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Exception name',\n",
       " 'ElementNotVisibleException',\n",
       " 'ElementNotSelectableException',\n",
       " 'NoSuchElementException',\n",
       " 'NoSuchFrameException',\n",
       " 'NoAlertPresentException',\n",
       " 'NoSuchWindowException',\n",
       " 'StaleElementReferenceException',\n",
       " 'SessionNotFoundException',\n",
       " 'TimeoutException',\n",
       " 'WebDriverException',\n",
       " 'ConnectionClosedException',\n",
       " 'ElementClickInterceptedException',\n",
       " 'ElementNotInteractableException',\n",
       " 'ErrorInResponseException',\n",
       " 'ErrorHandler.UnknownServerException',\n",
       " 'ImeActivationFailedException',\n",
       " 'ImeNotAvailableException',\n",
       " 'InsecureCertificateException',\n",
       " 'InvalidArgumentException',\n",
       " 'InvalidCookieDomainException',\n",
       " 'InvalidCoordinatesException',\n",
       " 'InvalidElementStateExceptio',\n",
       " 'InvalidSessionIdException',\n",
       " 'InvalidSwitchToTargetException',\n",
       " 'JavascriptException',\n",
       " 'JsonException',\n",
       " 'NoSuchAttributeException',\n",
       " 'MoveTargetOutOfBoundsException',\n",
       " 'NoSuchContextException',\n",
       " 'NoSuchCookieException',\n",
       " 'NotFoundException',\n",
       " 'RemoteDriverServerException',\n",
       " 'ScreenshotException',\n",
       " 'SessionNotCreatedException',\n",
       " 'UnableToSetCookieException',\n",
       " 'UnexpectedTagNameException',\n",
       " 'UnhandledAlertException',\n",
       " 'UnexpectedAlertPresentException',\n",
       " 'UnknownMethodException',\n",
       " 'UnreachableBrowserException',\n",
       " 'UnsupportedCommandException']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping name of exception\n",
    "name=[]\n",
    "\n",
    "try:\n",
    "    nm=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\")\n",
    "    \n",
    "    for i in nm:\n",
    "        name.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    name.append(\"No data found\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    name.append(\"No data found\")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44657b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Description',\n",
       " 'This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.',\n",
       " 'This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.',\n",
       " 'This Exception occurs if an element could not be found.',\n",
       " 'This Exception occurs if the frame target to be switched to does not exist.',\n",
       " 'This Exception occurs when you switch to no presented alert.',\n",
       " 'This Exception occurs if the window target to be switch does not exist.',\n",
       " 'This Selenium exception occurs happens when the web element is detached from the current DOM.',\n",
       " 'The WebDriver is acting after you quit the browser.',\n",
       " \"Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn't found in the specified time.\",\n",
       " 'This Exception takes place when the WebDriver is acting right after you close the browser.',\n",
       " 'This type of Exception takes place when there is a disconnection in the driver.',\n",
       " 'The command may not be completed as the element receiving the events is concealing the element which was requested clicked.',\n",
       " 'This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.',\n",
       " 'This happens while interacting with the Firefox extension or the remote driver server.',\n",
       " 'Exception is used as a placeholder in case if the server returns an error without a stack trace.',\n",
       " 'This expectation will occur when IME engine activation has failed.',\n",
       " 'It takes place when IME support is unavailable.',\n",
       " 'Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.',\n",
       " 'It occurs when an argument does not belong to the expected type.',\n",
       " 'This happens when you try to add a cookie under a different domain instead of current URL.',\n",
       " 'This type of Exception matches an interacting operation that is not valid.',\n",
       " \"It occurs when command can't be finished when the element is invalid.\",\n",
       " 'This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.',\n",
       " 'This occurs when the frame or window target to be switched does not exist.',\n",
       " 'This issue occurs while executing JavaScript given by the user.',\n",
       " 'It occurs when you afford to get the session when the session is not created.',\n",
       " 'This kind of Exception occurs when the attribute of an element could not be found.',\n",
       " 'It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.',\n",
       " 'ContextAware does mobile device testing.',\n",
       " 'This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.',\n",
       " 'This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.',\n",
       " 'This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.',\n",
       " 'It is not possible to capture a screen.',\n",
       " 'It happens when a new session could not be successfully created.',\n",
       " 'This occurs if a driver is unable to set a cookie.',\n",
       " 'Happens if a support class did not get a web element as expected.',\n",
       " 'This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.',\n",
       " 'It occurs when there is the appearance of an unexpected alert.',\n",
       " 'This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.',\n",
       " 'This Exception occurs only when the browser is not able to be opened or crashed because of some reason.',\n",
       " \"This occurs when remote WebDriver does n't send valid commands as expected.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping description of exception\n",
    "desc=[]\n",
    "\n",
    "try:\n",
    "    desc_tag=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\")\n",
    "    \n",
    "    for i in desc_tag:\n",
    "        desc.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    desc.append(\"No data found\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    desc.append(\"No data found\")\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8aee388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exception name</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name  \\\n",
       "0                 Exception name   \n",
       "1     ElementNotVisibleException   \n",
       "2  ElementNotSelectableException   \n",
       "3         NoSuchElementException   \n",
       "4           NoSuchFrameException   \n",
       "\n",
       "                                         Description  \n",
       "0                                        Description  \n",
       "1  This type of Selenium exception occurs when an...  \n",
       "2  This Selenium exception occurs when an element...  \n",
       "3  This Exception occurs if an element could not ...  \n",
       "4  This Exception occurs if the frame target to b...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating Dataframe\n",
    "Exception=pd.DataFrame()\n",
    "Exception[\"Name\"]=name\n",
    "Exception[\"Description\"]=desc\n",
    "Exception.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dab6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b1a036",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP at current price (19-20)\n",
    "D) GSDP at current price (18-19)\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ea11fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Getting url\n",
    "url= \"http://statisticstimes.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1691aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eco=driver.find_element_by_xpath(\"//div[@id='top']/div[2]/div[2]/button\")\n",
    "eco.click()\n",
    "\n",
    "ind=driver.find_element_by_xpath(\"//div[@id='top']/div[2]/div[2]/div/a[3]\")\n",
    "ind.click()\n",
    "\n",
    "try:\n",
    "    pop=driver.find_element_by_xpath(\"//span(@class='ns-6ksjd-e-16')\")\n",
    "    pop.click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "ingdp=driver.find_element_by_xpath(u\"//a[contains(text(),'» GDP of Indian states')]\")\n",
    "ingdp.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31834d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Scraping rank of state\n",
    "rank=[]\n",
    "try:\n",
    "    rnk=driver.find_elements_by_xpath(\"//tr[@role='row']/td[1]\")\n",
    "    for i in rnk:\n",
    "        rank.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    rank.append(\"No data found\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    rank.append(\"No data found\")\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a54a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping for state name\n",
    "state=[]\n",
    "try:\n",
    "    stt=driver.find_elements_by_xpath(\"//tr[@role='row']/td[2]\")\n",
    "    for i in stt:\n",
    "        state.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    state.append(\"No data found\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    state.append(\"No data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af61e58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '1,845,853',\n",
       " '1,687,818',\n",
       " '-',\n",
       " '1,631,977',\n",
       " '1,253,832',\n",
       " '1,020,989',\n",
       " '972,782',\n",
       " '969,604',\n",
       " '906,672',\n",
       " '-',\n",
       " '856,112',\n",
       " '831,610',\n",
       " '611,804',\n",
       " '574,760',\n",
       " '521,275',\n",
       " '-',\n",
       " '329,180',\n",
       " '328,598',\n",
       " '-',\n",
       " '-',\n",
       " '165,472',\n",
       " '80,449',\n",
       " '55,984',\n",
       " '-',\n",
       " '38,253',\n",
       " '36,572',\n",
       " '32,496',\n",
       " '31,790',\n",
       " '-',\n",
       " '-',\n",
       " '26,503',\n",
       " '-',\n",
       " '-',\n",
       " '1,659,210',\n",
       " '1,495,758',\n",
       " '1,476,983',\n",
       " '-',\n",
       " '1,150,711',\n",
       " '916,014',\n",
       " '881,873',\n",
       " '875,429',\n",
       " '827,019',\n",
       " '-',\n",
       " '779,647',\n",
       " '755,790',\n",
       " '562,710',\n",
       " '517,521',\n",
       " '457,757',\n",
       " '-',\n",
       " '301,242',\n",
       " '288,041',\n",
       " '-',\n",
       " '143,063',\n",
       " '-',\n",
       " '72,181',\n",
       " '50,227',\n",
       " '-',\n",
       " '34,823',\n",
       " '32,833',\n",
       " '29,148',\n",
       " '28,391',\n",
       " '-',\n",
       " '-',\n",
       " '24,424',\n",
       " '-']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping for GSDP(19-20)\n",
    "gsdp_y1=[]\n",
    "try:\n",
    "    gsdp=driver.find_elements_by_xpath(\"//tr[@role='row']/td[3]\")\n",
    "    for i in gsdp:\n",
    "        gsdp_y1.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    gsdp_y1.append(\"No data found\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    gsdp_y1.append(\"No data found\")\n",
    "gsdp_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad5fa173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723',\n",
       " '27,870',\n",
       " '27,283',\n",
       " '24,603',\n",
       " '22,287',\n",
       " '-',\n",
       " '2,332,992',\n",
       " '1,465,361',\n",
       " '1,404,761',\n",
       " '1,351,553',\n",
       " '1,322,936',\n",
       " '995,502',\n",
       " '845,247',\n",
       " '782,370',\n",
       " '776,140',\n",
       " '737,156',\n",
       " '707,542',\n",
       " '704,529',\n",
       " '666,075',\n",
       " '486,776',\n",
       " '472,506',\n",
       " '428,031',\n",
       " '282,782',\n",
       " '271,990',\n",
       " '266,537',\n",
       " '221,871',\n",
       " '133,303',\n",
       " '129,877',\n",
       " '66,060',\n",
       " '44,835',\n",
       " '37,571',\n",
       " '31,415',\n",
       " '29,544',\n",
       " '25,323',\n",
       " '25,141',\n",
       " '24,534',\n",
       " '22,488',\n",
       " '20,947',\n",
       " '-']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping for GSDP(18-19)\n",
    "gsdp_y2=[]\n",
    "try:\n",
    "    gsdp=driver.find_elements_by_xpath(\"//tr[@role='row']/td[4]\")\n",
    "    for i in gsdp:\n",
    "        gsdp_y2.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    gsdp_y2.append(\"No data found\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    gsdp_y2.append(\"No data found\")\n",
    "gsdp_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d5fca14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.94%',\n",
       " '8.63%',\n",
       " '8.39%',\n",
       " '7.96%',\n",
       " '7.91%',\n",
       " '5.77%',\n",
       " '4.99%',\n",
       " '4.57%',\n",
       " '4.56%',\n",
       " '4.29%',\n",
       " '4.14%',\n",
       " '4.10%',\n",
       " '3.89%',\n",
       " '2.81%',\n",
       " '2.79%',\n",
       " '2.58%',\n",
       " '1.67%',\n",
       " '1.61%',\n",
       " '1.57%',\n",
       " '1.30%',\n",
       " '0.83%',\n",
       " '0.81%',\n",
       " '0.39%',\n",
       " '0.26%',\n",
       " '0.22%',\n",
       " '0.18%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.14%',\n",
       " '0.13%',\n",
       " '0.12%',\n",
       " '-',\n",
       " '13.97%',\n",
       " '8.77%',\n",
       " '8.41%',\n",
       " '8.09%',\n",
       " '7.92%',\n",
       " '5.96%',\n",
       " '5.06%',\n",
       " '4.68%',\n",
       " '4.65%',\n",
       " '4.41%',\n",
       " '4.24%',\n",
       " '4.22%',\n",
       " '3.99%',\n",
       " '2.91%',\n",
       " '2.83%',\n",
       " '2.56%',\n",
       " '1.69%',\n",
       " '1.63%',\n",
       " '1.60%',\n",
       " '1.33%',\n",
       " '0.80%',\n",
       " '0.78%',\n",
       " '0.40%',\n",
       " '0.27%',\n",
       " '0.22%',\n",
       " '0.19%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.13%',\n",
       " '0.13%',\n",
       " '-']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapig Share data for each state\n",
    "share=[]\n",
    "try:\n",
    "    shr=driver.find_elements_by_xpath(\"//tr[@role='row']/td[5]\")\n",
    "    for i in shr:\n",
    "        share.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    share.append(\"No data found\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    share.append(\"No data found\")\n",
    "share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc37dfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-',\n",
       " '-',\n",
       " '1,167,776',\n",
       " '1,015,735',\n",
       " '1,035,131',\n",
       " '-',\n",
       " '713,376',\n",
       " '630,693',\n",
       " '594,806',\n",
       " '595,605',\n",
       " '496,798',\n",
       " '-',\n",
       " '568,265',\n",
       " '514,983',\n",
       " '377,276',\n",
       " '374,015',\n",
       " '344,437',\n",
       " '-',\n",
       " '218,232',\n",
       " '210,837',\n",
       " '-',\n",
       " '107,171',\n",
       " '-',\n",
       " '56,810',\n",
       " '35,980',\n",
       " '-',\n",
       " '22,291',\n",
       " '23,564',\n",
       " '18,549',\n",
       " '17,060',\n",
       " '-',\n",
       " '-',\n",
       " '17,797',\n",
       " '-']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping GDP for each state\n",
    "gdp=[]\n",
    "\n",
    "try:\n",
    "    gdp_t=driver.find_elements_by_xpath(\"//tr[@role='row']/td[6]\")\n",
    "    for i in gdp_t:\n",
    "        gdp.append(i.text)\n",
    "        \n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    gdp.append(\"No data found\")\n",
    "    \n",
    "except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "    gdp.append(\"No data found\")\n",
    "    \n",
    "gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f434ec57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           State GSDP(19-20) GSDP(18-19)   Share      GDP\n",
       "1    Maharashtra           -   2,632,792  13.94%  399.921\n",
       "2     Tamil Nadu   1,845,853   1,630,208   8.63%  247.629\n",
       "3  Uttar Pradesh   1,687,818   1,584,764   8.39%  240.726\n",
       "4        Gujarat           -   1,502,899   7.96%  228.290\n",
       "5      Karnataka   1,631,977   1,493,127   7.91%  226.806"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data frame\n",
    "GDP_state=pd.DataFrame()\n",
    "GDP_state[\"State\"]=state\n",
    "GDP_state[\"GSDP(19-20)\"]=gsdp_y1\n",
    "GDP_state[\"GSDP(18-19)\"]=gsdp_y2\n",
    "GDP_state[\"Share\"]=share\n",
    "GDP_state[\"GDP\"]=gdp\n",
    "GDP_state.index=rank\n",
    "GDP_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ef45fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac985b",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09e96b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Getting url\n",
    "url= \"https://github.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb6bb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex=driver.find_element_by_xpath(\"//summary[contains(text(),'Explore')]\")\n",
    "ex.click()\n",
    "\n",
    "tren=driver.find_element_by_xpath(\"//a[contains(text(),'Trending')]\")\n",
    "tren.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9b3dfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/commaai/openpilot',\n",
       " 'https://github.com/Azure/azure-sdk-for-net',\n",
       " 'https://github.com/bytedance/Fastbot_iOS',\n",
       " 'https://github.com/clouDr-f2e/rubick',\n",
       " 'https://github.com/MoienTajik/AspNetCore-Developer-Roadmap',\n",
       " 'https://github.com/microsoft/ML-For-Beginners',\n",
       " 'https://github.com/apache/pinot',\n",
       " 'https://github.com/SigmaHQ/sigma',\n",
       " 'https://github.com/ibraheemdev/modern-unix',\n",
       " 'https://github.com/klezVirus/inceptor',\n",
       " 'https://github.com/0x727/SqlKnife_0x727',\n",
       " 'https://github.com/mytechnotalent/Reverse-Engineering',\n",
       " 'https://github.com/sysprog21/lkmpg',\n",
       " 'https://github.com/microsoft/PowerToys',\n",
       " 'https://github.com/RasaHQ/rasa',\n",
       " 'https://github.com/geekxh/hello-algorithm',\n",
       " 'https://github.com/terraform-aws-modules/terraform-aws-eks',\n",
       " 'https://github.com/riscv2os/riscv2os',\n",
       " 'https://github.com/0x727/ShuiZe_0x727',\n",
       " 'https://github.com/ryanmcdermott/clean-code-javascript',\n",
       " 'https://github.com/vlang/v',\n",
       " 'https://github.com/MunGell/awesome-for-beginners',\n",
       " 'https://github.com/doocs/jvm',\n",
       " 'https://github.com/JetBrains/compose-jb',\n",
       " 'https://github.com/eugenp/tutorials']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ul=[]\n",
    "ul_t=driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\")\n",
    "for i in ul_t:\n",
    "    ul.append(i.get_attribute(\"href\"))\n",
    "ul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c9e73656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['commaai/openpilot', 'Azure/azure-sdk-for-net', 'bytedance/Fastbot_iOS', 'clouDr-f2e/rubick', 'MoienTajik/AspNetCore-Developer-Roadmap', 'microsoft/ML-For-Beginners', 'apache/pinot', 'SigmaHQ/sigma', 'ibraheemdev/modern-unix', 'klezVirus/inceptor', '0x727/SqlKnife_0x727', 'mytechnotalent/Reverse-Engineering', 'sysprog21/lkmpg', 'microsoft/PowerToys', 'RasaHQ/rasa', 'geekxh/hello-algorithm', 'terraform-aws-modules/terraform-aws-eks', 'riscv2os/riscv2os', '0x727/ShuiZe_0x727']\n",
      "['openpilot is an open source driver assistance system. openpilot performs the functions of Automated Lane Centering and Adaptive Cruise Control for over 100 supported car makes and models.', 'This repository is for active development of the Azure SDK for .NET. For consumers of the SDK we recommend visiting our public developer docs at https://docs.microsoft.com/en-us/dotnet/azure/ or our versioned developer docs at https://azure.github.io/azure-sdk-for-net.', 'About Fastbot(2.0) is a model-based testing tool for modeling GUI transitions to discover app stability problems', '基于 electron 的开源工具箱，自由集成丰富插件。', 'Roadmap to becoming an ASP.NET Core developer in 2021', '12 weeks, 25 lessons, 50 quizzes, classic Machine Learning for all', 'Apache Pinot (Incubating) - A realtime distributed OLAP datastore', 'Generic Signature Format for SIEM Systems', 'A collection of modern/faster/saner alternatives to common unix commands.', 'Template-Driven AV/EDR Evasion Framework', '适合在命令行中使用的轻巧的SQL Server数据库安全检测工具', 'A FREE comprehensive reverse engineering course covering x86, x64, 32-bit ARM & 64-bit ARM architectures.', 'The Linux Kernel Module Programming Guide (updated for 5.x kernels)', 'Windows system utilities to maximize productivity', 'Open source machine learning framework to automate text- and voice-based conversations: NLU, dialogue management, connect to Slack, Facebook, and more - Create chatbots and voice assistants', '针对小白的算法训练 | 包括四部分：①.算法基础 ②.力扣图解 ③.大厂面经 ④.CS_汇总 | 附：1、千本开源电子书 2、百张技术思维导图（项目花了上百小时，希望可以点 star 支持，感谢~）', 'Terraform module to create an Elastic Kubernetes (EKS) cluster and associated worker instances on AWS', '從 RISC-V 處理器到 UNIX 作業系統', '信息收集自动化工具']\n",
      "['', '', 'No Data found', 'muwoo 木偶', '', '', '', '', '', 'No Data found', 'No Data found', 'No Data found', '', '', '', '', '', 'ccckmit 陳鍾誠', 'No Data found']\n",
      "['C++50.0%', 'C#91.1%', 'Objective-C75.4%', 'JavaScript62.0%', 'No Data found', 'Jupyter Notebook99.4%', 'Java96.4%', 'Python97.8%', 'No Data found', 'Assembly69.9%', 'C++51.2%', 'C100.0%', 'TeX99.4%', 'C#49.8%', 'Python99.3%', 'Java100.0%', 'HCL85.7%', 'No Data found', 'Python99.8%']\n"
     ]
    }
   ],
   "source": [
    "name=[]\n",
    "desc=[]\n",
    "cont=[]\n",
    "lang=[]\n",
    "\n",
    "for i in (range(len(url))):\n",
    "    driver.get(ul[i])\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Scraping name of repository\n",
    "    try:\n",
    "        nm=driver.find_element_by_xpath(\"//h1[@class=' d-flex flex-wrap flex-items-center break-word f3 text-normal']\")\n",
    "        name.append(nm.text.replace(\"\\n\",\"\"))\n",
    "        \n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        name.append(\"No Data found\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        name.append(\"No Data found\")\n",
    "        \n",
    "    # Scraping description of repository\n",
    "    try:\n",
    "        desc_t=driver.find_element_by_xpath(\"//p[@class='f4 mt-3']\")\n",
    "        desc.append(desc_t.text.replace(\"\\n\",\"\"))\n",
    "        \n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        desc.append(\"No Data found\")\n",
    "    \n",
    "    except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "        desc.append(\"No Data found\")\n",
    "        \n",
    "        # Scraping contributers count in repository\n",
    "    try:\n",
    "        cont_t=driver.find_element_by_xpath(\"(.//*[contains(text(),'Contributors')])/following::span\")\n",
    "        cont.append(cont_t.text.replace(\"\\n\",\"\"))\n",
    "        \n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        cont.append(\"No Data found\")\n",
    "    \n",
    "    except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "        cont.append(\"No Data found\")\n",
    "\n",
    "        # Scraping language used in repository\n",
    "    try:\n",
    "        lng_t=driver.find_element_by_xpath(\"//a[@class='d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline text-small mr-3']\")\n",
    "        lang.append(lng_t.text.replace(\"\\n\",\"\"))\n",
    "        \n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        lang.append(\"No Data found\")\n",
    "    \n",
    "    except StaleElemnetReferenceException:  #handling Stale element exception\n",
    "        lang.append(\"No Data found\")\n",
    "\n",
    "print(name)\n",
    "print(desc)\n",
    "print(cont)\n",
    "print(lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9c30e2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language</th>\n",
       "      <th>Contributers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commaai/openpilot</td>\n",
       "      <td>openpilot is an open source driver assistance ...</td>\n",
       "      <td>C++50.0%</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure/azure-sdk-for-net</td>\n",
       "      <td>This repository is for active development of t...</td>\n",
       "      <td>C#91.1%</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bytedance/Fastbot_iOS</td>\n",
       "      <td>About Fastbot(2.0) is a model-based testing to...</td>\n",
       "      <td>Objective-C75.4%</td>\n",
       "      <td>No Data found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clouDr-f2e/rubick</td>\n",
       "      <td>基于 electron 的开源工具箱，自由集成丰富插件。</td>\n",
       "      <td>JavaScript62.0%</td>\n",
       "      <td>muwoo 木偶</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MoienTajik/AspNetCore-Developer-Roadmap</td>\n",
       "      <td>Roadmap to becoming an ASP.NET Core developer ...</td>\n",
       "      <td>No Data found</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name  \\\n",
       "0                        commaai/openpilot   \n",
       "1                  Azure/azure-sdk-for-net   \n",
       "2                    bytedance/Fastbot_iOS   \n",
       "3                        clouDr-f2e/rubick   \n",
       "4  MoienTajik/AspNetCore-Developer-Roadmap   \n",
       "\n",
       "                                         Description          Language  \\\n",
       "0  openpilot is an open source driver assistance ...          C++50.0%   \n",
       "1  This repository is for active development of t...           C#91.1%   \n",
       "2  About Fastbot(2.0) is a model-based testing to...  Objective-C75.4%   \n",
       "3                       基于 electron 的开源工具箱，自由集成丰富插件。   JavaScript62.0%   \n",
       "4  Roadmap to becoming an ASP.NET Core developer ...     No Data found   \n",
       "\n",
       "  Contributers_count  \n",
       "0                     \n",
       "1                     \n",
       "2      No Data found  \n",
       "3           muwoo 木偶  \n",
       "4                     "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "repo=pd.DataFrame()\n",
    "repo[\"Name\"]=name\n",
    "repo[\"Description\"]=desc\n",
    "repo[\"Language\"]=lang\n",
    "repo[\"Contributers_count\"]=cont\n",
    "repo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1dbc14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d095bebd",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04dba7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# Getting url\n",
    "url= \"https://www.billboard.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0238a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop= driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/nav/ul/li[3]/a\")\n",
    "drop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9059b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Song name\n",
    "name=[]\n",
    "try:\n",
    "    nm=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "    for i in nm:\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    name.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    name.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7df2451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping song artist\n",
    "artst=[]\n",
    "try:\n",
    "    artst_tag=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "    for i in artst_tag:\n",
    "        artst.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    artst.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    artst.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6110ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping rank of song last week\n",
    "lw=[]\n",
    "try:\n",
    "    lw_tag=driver.find_elements_by_xpath(\"//span[@class='chart-element__metas chart-element__metas--small display--flex']/span[1]\")\n",
    "    for i in lw_tag:\n",
    "        lw.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    lw.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    lw.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c44394a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping peak rank of song\n",
    "pk=[]\n",
    "try:\n",
    "    pk_tag=driver.find_elements_by_xpath(\"//span[@class='chart-element__metas chart-element__metas--small display--flex']/span[2]\")\n",
    "    for i in pk_tag:\n",
    "        pk.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    pk.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    pk.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36476f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping for week on chart\n",
    "woc=[]\n",
    "try:\n",
    "    woc_tag=driver.find_elements_by_xpath(\"//span[@class='chart-element__metas chart-element__metas--small display--flex']/span[3]\")\n",
    "    for i in woc_tag:\n",
    "        woc.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    woc.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    woc.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1777200c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>LastWeek Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1 LW</td>\n",
       "      <td>1 Pk</td>\n",
       "      <td>10 WoC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Industry Baby</td>\n",
       "      <td>Lil Nas X &amp; Jack Harlow</td>\n",
       "      <td></td>\n",
       "      <td>2 Pk</td>\n",
       "      <td>1 WoC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2 LW</td>\n",
       "      <td>1 Pk</td>\n",
       "      <td>11 WoC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>4 LW</td>\n",
       "      <td>3 Pk</td>\n",
       "      <td>3 WoC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>3 LW</td>\n",
       "      <td>2 Pk</td>\n",
       "      <td>43 WoC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Song Name                         Artist LastWeek Rank Peak Rank  \\\n",
       "0         Butter                            BTS          1 LW      1 Pk   \n",
       "1  Industry Baby        Lil Nas X & Jack Harlow                    2 Pk   \n",
       "2       Good 4 U                 Olivia Rodrigo          2 LW      1 Pk   \n",
       "3           Stay  The Kid LAROI & Justin Bieber          4 LW      3 Pk   \n",
       "4     Levitating      Dua Lipa Featuring DaBaby          3 LW      2 Pk   \n",
       "\n",
       "  Weeks on Chart  \n",
       "0         10 WoC  \n",
       "1          1 WoC  \n",
       "2         11 WoC  \n",
       "3          3 WoC  \n",
       "4         43 WoC  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a data frame\n",
    "Top100_songs=pd.DataFrame()\n",
    "Top100_songs[\"Song Name\"]=name\n",
    "Top100_songs[\"Artist\"]=artst\n",
    "Top100_songs[\"LastWeek Rank\"]=lw\n",
    "Top100_songs[\"Peak Rank\"]=pk\n",
    "Top100_songs[\"Weeks on Chart\"]=woc\n",
    "Top100_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "88419204",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850382f9",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c80468d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "22dbdeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.naukri.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c80505ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pg=driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/div/ul[1]/li[2]/a\")\n",
    "new_page=new_pg.get_attribute(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "050bc345",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(new_page) # to open recruiters page\n",
    "time.sleep(2)\n",
    "\n",
    "search=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input\")\n",
    "search.send_keys(\"Data Science\")\n",
    "\n",
    "btn=driver.find_element_by_id(\"qsbFormBtn\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3f3c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "url_t=driver.find_elements_by_xpath(\"//a[@class='ellipsis']\")\n",
    "for i in url_t:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "051f3cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "desg=[]\n",
    "comp_name=[]\n",
    "skills=[]\n",
    "loc=[]\n",
    "\n",
    "for i in (range(len(urls))):\n",
    "    driver.get(urls[i])\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Scraping Recruiter's name\n",
    "    try:\n",
    "        nm=driver.find_element_by_xpath(\"//h1[@class='fl ellipsis wLimit hd']\")\n",
    "        name.append(nm.text)\n",
    "\n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        name.append(\"No Data found\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        name.append(\"No Data found\")\n",
    "\n",
    "    # Scraping Designation of recruiter\n",
    "    try:\n",
    "        desg_t=driver.find_element_by_xpath(\"//div[@class='rFrame fl infoWrapper']\")\n",
    "        desg.append(desg_t.text)\n",
    "\n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        desg.append(\"No Data found\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        desg.append(\"No Data found\")\n",
    "\n",
    "    # Scraping Company of recruiter\n",
    "    try:\n",
    "        comp=driver.find_element_by_xpath(\"//div[@class='rFrame fl infoWrapper']/div[4]\")\n",
    "        comp_name.append(comp.text)\n",
    "\n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        comp_name.append(\"No Data found\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        comp_name.append(\"No Data found\")\n",
    "\n",
    "    # Scraping skills they hire for\n",
    "    try:\n",
    "        skl=driver.find_element_by_xpath(\"//div[@class='fl lPortn']/p\")\n",
    "        skills.append(skl.text)\n",
    "\n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        skills.append(\"No Data found\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        skills.append(\"No Data found\")\n",
    "        \n",
    "    # Scraping location of recruiter\n",
    "    try:\n",
    "        loc_t=driver.find_element_by_xpath(\"//div[@class=''rFrame fl infoWrapper']/div[5]\")\n",
    "        loc.append(loc_t.text)\n",
    "    \n",
    "    except NoSuchElementException:  #handling no such element exception\n",
    "        loc.append(\"No Data found\")\n",
    "    \n",
    "    except StaleElementReferenceException:  #handling Stale element exception\n",
    "        loc.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33133a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>Aakash Harit\\nHR Manager\\nData Science Network...</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>No Data found</td>\n",
       "      <td>Classic ASP Developer , Internet Marketing Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Data found</td>\n",
       "      <td>No Data found</td>\n",
       "      <td>No Data found</td>\n",
       "      <td>No Data found</td>\n",
       "      <td>No Data found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>shravan Kumar Gaddam\\nCompany Recruiter\\nShore...</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>No Data found</td>\n",
       "      <td>.Net , Java , Data Science , Linux Administrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Data found</td>\n",
       "      <td>No Data found</td>\n",
       "      <td>No Data found</td>\n",
       "      <td>No Data found</td>\n",
       "      <td>No Data found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>MARSIAN Technologies LLP\\nCompany HR\\nMARSIAN ...</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>No Data found</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name  \\\n",
       "0              Aakash Harit   \n",
       "1             No Data found   \n",
       "2      shravan Kumar Gaddam   \n",
       "3             No Data found   \n",
       "4  MARSIAN Technologies LLP   \n",
       "\n",
       "                                         Designation  \\\n",
       "0  Aakash Harit\\nHR Manager\\nData Science Network...   \n",
       "1                                      No Data found   \n",
       "2  shravan Kumar Gaddam\\nCompany Recruiter\\nShore...   \n",
       "3                                      No Data found   \n",
       "4  MARSIAN Technologies LLP\\nCompany HR\\nMARSIAN ...   \n",
       "\n",
       "                         Company       Location  \\\n",
       "0           Data Science Network  No Data found   \n",
       "1                  No Data found  No Data found   \n",
       "2  Shore Infotech India Pvt. Ltd  No Data found   \n",
       "3                  No Data found  No Data found   \n",
       "4       MARSIAN Technologies LLP  No Data found   \n",
       "\n",
       "                                              Skills  \n",
       "0  Classic ASP Developer , Internet Marketing Pro...  \n",
       "1                                      No Data found  \n",
       "2  .Net , Java , Data Science , Linux Administrat...  \n",
       "3                                      No Data found  \n",
       "4                            Mid Level, Junior Level  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data frame\n",
    "Recruiters=pd.DataFrame()\n",
    "Recruiters[\"Name\"]=name\n",
    "Recruiters[\"Designation\"]=desg\n",
    "Recruiters[\"Company\"]=comp_name\n",
    "Recruiters[\"Location\"]=loc\n",
    "Recruiters[\"Skills\"]=skills\n",
    "Recruiters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25aabba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd89ba4",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8aebfcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ea98ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "driver.get(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3b3c55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book name\n",
    "name=[]\n",
    "try:\n",
    "    nm=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "    for i in nm:\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    name.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    name.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1a9a1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping author name\n",
    "author=[]\n",
    "try:\n",
    "    auth=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "    for i in auth:\n",
    "        author.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    author.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    author.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "21ac7f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Volumes sold\n",
    "vol_sold=[]\n",
    "try:\n",
    "    vol=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "    for i in vol:\n",
    "        vol_sold.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    vol_sold.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    vol_sold.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08c9820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Publisher name\n",
    "pub=[]\n",
    "try:\n",
    "    pub_t=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "    for i in pub_t:\n",
    "        pub.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    pub.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    pub.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0848baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping genre of book\n",
    "gnr=[]\n",
    "try:\n",
    "    gnr_t=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "    for i in gnr_t:\n",
    "        gnr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    gnr.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    gnr.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3960b8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Book_Name         Author Volume Sold  \\\n",
       "0                          Da Vinci Code,The     Brown, Dan   5,094,805   \n",
       "1       Harry Potter and the Deathly Hallows  Rowling, J.K.   4,475,152   \n",
       "2   Harry Potter and the Philosopher's Stone  Rowling, J.K.   4,200,654   \n",
       "3  Harry Potter and the Order of the Phoenix  Rowling, J.K.   4,179,479   \n",
       "4                       Fifty Shades of Grey   James, E. L.   3,758,936   \n",
       "\n",
       "      Publisher                        Genre  \n",
       "0    Transworld  Crime, Thriller & Adventure  \n",
       "1    Bloomsbury           Children's Fiction  \n",
       "2    Bloomsbury           Children's Fiction  \n",
       "3    Bloomsbury           Children's Fiction  \n",
       "4  Random House              Romance & Sagas  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "Books_Sold=pd.DataFrame()\n",
    "Books_Sold[\"Book_Name\"]=name\n",
    "Books_Sold[\"Author\"]=author\n",
    "Books_Sold[\"Volume Sold\"]=vol_sold\n",
    "Books_Sold[\"Publisher\"]=pub\n",
    "Books_Sold[\"Genre\"]=gnr\n",
    "Books_Sold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "51f49845",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0a763",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    " Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d7717d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "33dc5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.imdb.com/list/ls095964455\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fa5319ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping TV Show name\n",
    "name=[]\n",
    "try:\n",
    "    nm=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in nm:\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    name.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    name.append(\"No Data found\")\n",
    "\n",
    "# Scraping span time of Tv show\n",
    "spn_tm=[]\n",
    "try:\n",
    "    spn=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in spn:\n",
    "        spn_tm.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    spn_tm.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    spn_tm.append(\"No Data found\")\n",
    "\n",
    "# Scraping genre of book\n",
    "gnr=[]\n",
    "try:\n",
    "    gnr_t=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "    for i in gnr_t:\n",
    "        gnr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    gnr.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    gnr.append(\"No Data found\")\n",
    "\n",
    "# Scraping runtime of TV Show\n",
    "rntm=[]\n",
    "try:\n",
    "    rntm_t=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "    for i in rntm_t:\n",
    "        rntm.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    rntm.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    rntm.append(\"No Data found\")\n",
    "\n",
    "# Scraping rating of TV Show\n",
    "rtng=[]\n",
    "try:\n",
    "    rt=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-widget']/div/span[2]\")\n",
    "    for i in rt:\n",
    "        rtng.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    rtng.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    rtng.append(\"No Data found\")\n",
    "\n",
    "# Scraping number of votes\n",
    "votes=[]\n",
    "try:\n",
    "    vt=driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p[4]/span[2]\")\n",
    "    for i in vt:\n",
    "        votes.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    votes.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    votes.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4d88cb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Span Time</th>\n",
       "      <th>Genre</th>\n",
       "      <th>RunTime</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Number_of_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,849,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>886,678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>886,284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>266,579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>227,072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name    Span Time                     Genre RunTime Ratings  \\\n",
       "0   Game of Thrones  (2011–2019)  Action, Adventure, Drama  57 min     9.2   \n",
       "1   Stranger Things     (2016– )    Drama, Fantasy, Horror  51 min     8.7   \n",
       "2  The Walking Dead  (2010–2022)   Drama, Horror, Thriller  44 min     8.2   \n",
       "3    13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller  60 min     7.6   \n",
       "4           The 100  (2014–2020)    Drama, Mystery, Sci-Fi  43 min     7.6   \n",
       "\n",
       "  Number_of_votes  \n",
       "0       1,849,399  \n",
       "1         886,678  \n",
       "2         886,284  \n",
       "3         266,579  \n",
       "4         227,072  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe\n",
    "TV_Shows=pd.DataFrame()\n",
    "TV_Shows[\"Name\"]=name\n",
    "TV_Shows[\"Span Time\"]=spn_tm\n",
    "TV_Shows[\"Genre\"]=gnr\n",
    "TV_Shows[\"RunTime\"]=rntm\n",
    "TV_Shows[\"Ratings\"]=rtng\n",
    "TV_Shows[\"Number_of_votes\"]=votes\n",
    "TV_Shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2fae4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cbdfe0",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    " Url = https://archive.ics.uci.edu/\n",
    " You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e1b07932",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61b73348",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url = \"https://archive.ics.uci.edu\"\n",
    "driver.get(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5cc64487",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td/span/b/a\")\n",
    "btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "45d6fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping name of datasets\n",
    "name=[]\n",
    "try:\n",
    "    nm=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "    for i in nm:\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    name.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    name.append(\"No Data found\")\n",
    "\n",
    "# Scraping Data types\n",
    "type_=[]\n",
    "try:\n",
    "    typ=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "    for i in typ:\n",
    "        type_.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    type_.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    type_.append(\"No Data found\")\n",
    "\n",
    "# Scraping default task\n",
    "task=[]\n",
    "try:\n",
    "    tsk=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]\")\n",
    "    for i in tsk:\n",
    "        task.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    task.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    task.append(\"No Data found\")\n",
    "\n",
    "# Scraping type of attributes\n",
    "type_attr=[]\n",
    "try:\n",
    "    typ_attr=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]\")\n",
    "    for i in typ_attr:\n",
    "        type_attr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    type_attr.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    type_attr.append(\"No Data found\")\n",
    "\n",
    "# Scraping Number of instances\n",
    "inst=[]\n",
    "try:\n",
    "    inst_t=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]\")\n",
    "    for i in inst_t:\n",
    "        inst.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    inst.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    inst.append(\"No Data found\")\n",
    "\n",
    "# Scraping Number of attributes\n",
    "attr=[]\n",
    "try:\n",
    "    attr_t=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]\")\n",
    "    for i in attr_t:\n",
    "        attr.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    attr.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    attr.append(\"No Data found\")\n",
    "\n",
    "# Scraping year \n",
    "year=[]\n",
    "try:\n",
    "    yr=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]\")\n",
    "    for i in yr:\n",
    "        year.append(i.text)\n",
    "\n",
    "except NoSuchElementException:  #handling no such element exception\n",
    "    year.append(\"No Data found\")\n",
    "    \n",
    "except StaleElementReferenceException:  #handling Stale element exception\n",
    "    year.append(\"No Data found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "750c1528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Default task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>Number of instances</th>\n",
       "      <th>Number of attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Types</td>\n",
       "      <td>Data Types</td>\n",
       "      <td>Default Task</td>\n",
       "      <td>Attribute Types</td>\n",
       "      <td># Instances</td>\n",
       "      <td># Attributes</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name      Data Type          Default task  \\\n",
       "0     Data Types     Data Types          Default Task   \n",
       "1  Multivariate   Multivariate        Classification    \n",
       "2  Multivariate   Multivariate        Classification    \n",
       "3  Multivariate   Multivariate        Classification    \n",
       "4                                Recommender-Systems    \n",
       "\n",
       "                Attribute type Number of instances Number of attributes   Year  \n",
       "0              Attribute Types         # Instances         # Attributes   Year  \n",
       "1  Categorical, Integer, Real                4177                    8   1995   \n",
       "2        Categorical, Integer               48842                   14   1996   \n",
       "3  Categorical, Integer, Real                 798                   38          \n",
       "4                 Categorical               37711                  294   1998   "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating dataframe\n",
    "DataSets=pd.DataFrame()\n",
    "DataSets[\"Name\"]=name\n",
    "DataSets[\"Data Type\"]=type_\n",
    "DataSets[\"Default task\"]=task\n",
    "DataSets[\"Attribute type\"]=type_attr\n",
    "DataSets[\"Number of instances\"]=inst\n",
    "DataSets[\"Number of attributes\"]=attr\n",
    "DataSets[\"Year\"]=year\n",
    "DataSets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f8ec0a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bad72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562fca90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3b256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efcb02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a6af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8b33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f5e8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
